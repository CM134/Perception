{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Project 5\n",
    "## Global Registration implementation.\n",
    "## Task 1\n",
    "Today your project is to implement a global registration algorithm.\n",
    "\n",
    "It should be able to roughly align two pointclouds.\n",
    "1. Implement global registration. You are allowed to use the FPHF features and have to implement the RANSAC algorithm\n",
    "\n",
    "2. Can you fit **r1.pcd** and **r2.pcd**?\n",
    "3. Can you fit **car1.ply** and **car2.ply**?\n",
    "These are in the *global_registration* folder\n",
    "\n",
    "\n",
    "\n",
    "## Task 2 (Challange)\n",
    "Challanges attempt either or both:\n",
    "- Implement local registration.\n",
    "\n",
    "- Attempt to reconstruct the car from the images in *car_challange* folder.\n",
    "\n",
    "You can use the exercises from monday as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ex1 \n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "    \n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def prepare_dataset(voxel_size, source, target):\n",
    "\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registrations(source, target)\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start tasks\n",
    "\n",
    "## Task 1.1\n",
    "\n",
    "Implementation of RANSAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n"
     ]
    }
   ],
   "source": [
    "r1 = o3d.io.read_point_cloud(\"global_registration/r1.pcd\")\n",
    "r2 = o3d.io.read_point_cloud(\"global_registration/r2.pcd\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "voxel_size = 0.05  # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size, r1, r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class with dimension = 33 and num = 4760\n",
      "Access its data via data member.\n"
     ]
    }
   ],
   "source": [
    "print(source_fpfh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 4760)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_fpfh.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "pairs [[2.65651144 1.82038296 1.95847255]\n",
      " [2.74108237 1.8374085  1.92926274]\n",
      " [1.59793512 2.39155427 1.80971246]\n",
      " [2.65651144 1.82038296 1.95847255]\n",
      " [2.69209885 1.75276119 1.94765851]\n",
      " [1.24125207 2.47926725 1.48932498]\n",
      " [2.69476938 1.84755864 1.87862467]\n",
      " [2.67578125 1.78515625 1.95342541]\n",
      " [2.69843292 1.8397372  1.92094711]\n",
      " [2.69549624 1.86066483 1.83049798]\n",
      " [2.69549624 1.86066483 1.83049798]\n",
      " [2.59382093 1.75808239 1.92316747]\n",
      " [2.79319797 1.84522867 1.88015007]\n",
      " [2.84348984 1.85909635 1.82805289]\n",
      " [2.64511556 1.75784289 1.93711793]\n",
      " [1.359375   2.53464043 1.30691612]\n",
      " [1.25738058 1.32349873 1.40850411]\n",
      " [2.7421875  1.88244079 1.75390625]\n",
      " [1.29478014 1.30970106 1.41664663]\n",
      " [2.38121362 1.70181906 1.84970964]\n",
      " [2.38121362 1.70181906 1.84970964]\n",
      " [2.41735705 1.68295427 1.85562408]\n",
      " [1.39400342 2.44329804 1.62624903]\n",
      " [1.33119343 1.54708706 1.50169589]\n",
      " [1.34949414 1.56348818 1.5121626 ]\n",
      " [2.17839489 1.74471688 1.80161164]\n",
      " [1.3226308  1.38932292 1.45130825]\n",
      " [1.19580565 1.50740271 1.11479893]\n",
      " [2.59377133 1.60843736 1.88092394]\n",
      " [2.54290672 1.60910437 1.86815371]\n",
      " [1.44490971 2.44365154 1.62674813]\n",
      " [1.44490971 2.44365154 1.62674813]\n",
      " [1.4917279  2.44412234 1.62835811]\n",
      " [1.54287373 2.44543078 1.62893984]\n",
      " [1.44629245 2.53591986 1.313549  ]\n",
      " [1.64457126 2.46213393 1.57986674]\n",
      " [1.26032207 1.47708007 1.45680912]\n",
      " [1.453125   2.43418819 1.66015625]\n",
      " [1.79267077 2.46067837 1.57886226]\n",
      " [2.54290672 1.60910437 1.86815371]\n",
      " [1.49362823 2.59143869 1.12216121]\n",
      " [1.36328795 1.87495439 1.60543559]\n",
      " [1.38361419 1.65368658 1.54790111]\n",
      " [1.74341692 2.41668769 1.73192906]\n",
      " [1.69875198 2.429968   1.68920908]\n",
      " [2.0920889  1.80728863 1.79350668]\n",
      " [1.27428321 1.44618843 1.4500247 ]\n",
      " [2.69546177 2.52476876 1.33072108]\n",
      " [2.69481761 1.5581181  1.89058085]\n",
      " [2.59377133 1.60843736 1.88092394]]\n",
      "index [1348, 3154, 1442, 1348, 2987, 2346, 2947, 3165, 3259, 2969, 2969, 3036, 2520, 1878, 1906, 122, 2136, 2500, 2129, 2927, 2927, 2930, 1592, 1798, 1967, 1311, 2035, 2336, 2634, 2677, 236, 236, 309, 308, 584, 1003, 1856, 2413, 127, 2677, 2953, 1455, 2573, 155, 3180, 2570, 1526, 220, 1233, 2634]\n",
      "target_down [2.76953125 2.58641648 1.10546875]\n"
     ]
    }
   ],
   "source": [
    "s = source_fpfh.data\n",
    "t = target_fpfh.data\n",
    "\n",
    "dist_t = np.zeros([target_fpfh.num(),1])\n",
    "index = []\n",
    "\n",
    "\n",
    "for u in range(50):\n",
    "        ps = s[:,u]\n",
    "        \n",
    "        for i in range(target_fpfh.num()):\n",
    "            pt = t[:,i]\n",
    "            dist_t[i] = np.linalg.norm(ps-pt)\n",
    "        \n",
    "        if u>= target_fpfh.num():\n",
    "            break\n",
    "        index.append(np.argmin(dist_t))\n",
    "        \n",
    "            \n",
    "pairs_target_points = np.asarray(target_down.points)[index,:]\n",
    "print(\"Done\")  \n",
    "print(\"pairs\",pairs_target_points)\n",
    "print(\"index\",index)\n",
    "print(\"target_down\",target_down.points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kabsch_template(A, B):\n",
    "    assert len(A) == len(B)\n",
    "    \n",
    "    \n",
    "    N = A.shape[0];  # total points\n",
    "\n",
    "    \n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "\n",
    "    # center the points\n",
    "    AA = A - np.tile(centroid_A, (N, 1))\n",
    "    BB = B - np.tile(centroid_B, (N, 1))\n",
    "\n",
    "    H = np.transpose(BB) * AA\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "\n",
    "    R = Vt.T * U.T\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        print(\"Reflection detected\")\n",
    "        Vt[2, :] *= -1\n",
    "        R = Vt.T * U.T\n",
    "\n",
    "    \n",
    "    t = -R * centroid_B.T + centroid_A.T\n",
    "\n",
    "    return R, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kabsch(A, B):\n",
    "    assert len(A) == len(B)\n",
    "    \n",
    "    \n",
    "    N = A.shape[0];  # total points\n",
    "\n",
    "    \n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "\n",
    "    # center the points\n",
    "    AA = A - centroid_A, (N, 1))\n",
    "    BB = B - np.tile(centroid_B, (N, 1))\n",
    "\n",
    "    H = np.transpose(BB) * AA\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "\n",
    "    R = Vt.T * U.T\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        print(\"Reflection detected\")\n",
    "        Vt[2, :] *= -1\n",
    "        R = Vt.T * U.T\n",
    "\n",
    "    \n",
    "    t = -R * centroid_B.T + centroid_A.T\n",
    "\n",
    "    return R, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[15., 10., 10.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.matrix([[10.0,10.0,10.0],\n",
    "               [20.0,10.0,10.0]])\n",
    "\n",
    "np.mean(A,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match target [[1.26032207 1.47708007 1.45680912]\n",
      " [2.65651144 1.82038296 1.95847255]\n",
      " [1.49362823 2.59143869 1.12216121]]\n",
      " \n",
      "match source [[2.40345446 1.6621175  2.10315653]\n",
      " [2.36328125 2.23442745 1.33203125]\n",
      " [2.39040141 1.91070131 1.39896627]]\n",
      "Reflection detected\n",
      "Kabsch result:\n",
      "R: [[-0.22798524 -0.01609472  0.27761715]\n",
      " [-0.47988754  0.22640732  0.18499097]\n",
      " [-0.1640291  -0.55642067 -0.10520919]]\n",
      "t [[2.37498225 2.01110513 1.41815106]\n",
      " [2.72715941 1.49090859 1.57892627]\n",
      " [2.28556706 3.17017038 2.08263909]]\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 1\n",
    "import random\n",
    "my_source = np.asarray(source_down.points)\n",
    "my_target = np.asarray(target_down.points)\n",
    "my_index = np.asarray(index)\n",
    "while max_iterations:\n",
    "            max_iterations -= 1\n",
    "            # Add 3 random indexes\n",
    "            random.seed()\n",
    "            inliers = []\n",
    "            n = 3\n",
    "            while len(inliers) < n:\n",
    "                random_index = random.randint(0, 50-1)\n",
    "                #random_index = random.randint(0, len(s[0,:])-1)\n",
    "                inliers.append(random_index)\n",
    "            match_source = my_source[inliers]\n",
    "            my_target_index = my_index[inliers]\n",
    "            match_target = my_target[my_target_index]\n",
    "            print(\"match target\",match_target)\n",
    "            print(\" \")\n",
    "            print(\"match source\",match_source)\n",
    "            \n",
    "            \n",
    "            R,t = Kabsch(match_source,match_target)\n",
    "            \n",
    "            print('Kabsch result:')\n",
    "            print('R:',R)\n",
    "            print('t',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(s[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale\n"
     ]
    }
   ],
   "source": [
    "scale = 3\n",
    "\n",
    "\n",
    "if scale:\n",
    "    print(\"scale\")\n",
    "else:\n",
    "    print(\"Hello\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
