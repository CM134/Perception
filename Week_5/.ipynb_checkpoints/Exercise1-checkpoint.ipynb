{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global registration with RANSAC\n",
    "We are going to use open3d (http://www.open3d.org/) to handle  pointclouds and generation of pointclouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "    source = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "    target = o3d.io.read_point_cloud(\"ICP/r2.pcd\")\n",
    "\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read in our pointclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"ICP/r2.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"ICP/r3.pcd\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "# Show models side by side\n",
    "draw_registrations(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding features in pointclouds\n",
    "When working on point clouds it can be benefitial work on a downsampled version of the point cloud.\n",
    "you can use [```pointcloudname.voxel_down_sample()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html) where pointcloud is the name of your point cloud object.\n",
    "\n",
    "We also need to estimate the normals of the pointcloud points using [```pointcloudname.estimate_normals()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html)\n",
    "\n",
    "And finally find fpfh features or correspondance of the downsampled point clouds.\n",
    "[```o3d.pipelines.registration.compute_fpfh_feature()```](http://www.open3d.org/docs/latest/python_api/open3d.pipelines.registration.compute_fpfh_feature.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Downsample and find features here\n",
    "####\n",
    "\n",
    "# Downsample the point cloud with a voxel of 0.05\n",
    "source_down = source.voxel_down_sample(voxel_size=0.05)\n",
    "o3d.visualization.draw_geometries([source_down],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])\n",
    "\n",
    "# Recompute the normal of the downsampled point cloud\n",
    "source_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "o3d.visualization.draw_geometries([source_down],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024],\n",
    "                                  point_show_normal=True)\n",
    "\n",
    "\n",
    "# Downsample and compute normals for target\n",
    "target_down = target.voxel_down_sample(voxel_size=0.05)\n",
    "target_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ransac\n",
    "We will now attempt to use ransac to do a global registration of the two poinclouds.\n",
    "\n",
    "Using the function [```o3d.pipelines.registration.registration_ransac_based_on_feature_matching```](http://www.open3d.org/docs/latest/python_api/open3d.pipelines.registration.registration_ransac_based_on_feature_matching.html) from open3d\n",
    "\n",
    "\n",
    "Try to find the transformation from r1 to r2.\n",
    "Attempt with point to point and point to plane\n",
    "```Python\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "```\n",
    "\n",
    "When using ransac focus on the arguments below the rest are optional\n",
    "```Python\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_point)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute FPFH feature with search radius 0.250.\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Call RANSAC here\n",
    "####\n",
    "\n",
    "# compute FPFH\n",
    "\n",
    "radius_feature = voxel_size * 5\n",
    "print(\"Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    source_down,\n",
    "    o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    target_down,\n",
    "    o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "\n",
    "\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "\n",
    "\n",
    "distance_threshold = voxel_size * 0.5 # from documentation\n",
    "\n",
    "ransac_result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_down, target_down, \n",
    "    source_fpfh, target_fpfh, True, \n",
    "    distance_threshold,\n",
    "    point_to_point)\n",
    "draw_registrations(source, target, ransac_result.transformation, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.050,\n",
      "   we use a liberal distance threshold 0.075.\n",
      "RegistrationResult with fitness=4.054848e-01, inlier_rmse=3.882035e-02, and correspondence_set size of 414\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "# voxel_size = 0.05  # means 5cm for this dataset\n",
    "# source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(\n",
    "#     voxel_size)\n",
    "# result_ransac = execute_global_registration(source_down, target_down,\n",
    "#                                             source_fpfh, target_fpfh,\n",
    "#                                             voxel_size)\n",
    "# print(result_ransac)\n",
    "# draw_registration_result(source_down, target_down, result_ransac.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "### A)\n",
    "    Can you get a decent transformation from r1 to r3?\n",
    "### B)\n",
    "    with the following checkers can you get better results from RANSAC? Try tweaking the parameters of them Can you make Point to Plane work do not spend too long on this if you cant skip it. (I was not able to get a good fit)\n",
    "\n",
    "You can also try tweaking the voxel_size\n",
    "```Python\n",
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "c0 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "cecker_list = [c0,c1,c2]\n",
    "\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True,\n",
    "    distance_threshold,\n",
    "    point_to_point,\n",
    "    checkers = checker_list)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
