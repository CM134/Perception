{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Project 5\n",
    "## Global Registration implementation.\n",
    "## Task 1\n",
    "Today your project is to implement a global registration algorithm.\n",
    "\n",
    "It should be able to roughly align two pointclouds.\n",
    "1. Implement global registration. You are allowed to use the FPHF features and have to implement the RANSAC algorithm\n",
    "\n",
    "2. Can you fit **r1.pcd** and **r2.pcd**?\n",
    "3. Can you fit **car1.ply** and **car2.ply**?\n",
    "These are in the *global_registration* folder\n",
    "\n",
    "\n",
    "\n",
    "## Task 2 (Challange)\n",
    "Challanges attempt either or both:\n",
    "- Implement local registration.\n",
    "\n",
    "- Attempt to reconstruct the car from the images in *car_challange* folder.\n",
    "\n",
    "You can use the exercises from monday as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ex1 \n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "    \n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def prepare_dataset(voxel_size, source, target):\n",
    "\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registrations(source, target)\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start tasks\n",
    "\n",
    "## Task 1.1\n",
    "\n",
    "Implementation of RANSAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. find pairs in fpfh (source <-> target)\n",
    "2. take N number of pairs and run Kabsch -> rot, trans = tranformation\n",
    "3. applying transformation\n",
    "4. calc distance of pairs and sum = error\n",
    "5. find best model\n",
    "\n",
    " \n",
    "### PSEUDOCODE\n",
    " \n",
    " ```\n",
    " RANSAC(k=maxinter, n= numberofrandompoints, source_fpfh, target)\n",
    " \n",
    " for ALL source\n",
    "     onesource\n",
    "     for all target\n",
    "         onetarget\n",
    "         dist = norm(1sou-1tar)\n",
    " \n",
    " vector_sorted_source\n",
    " vector _ target\n",
    " \n",
    " while iter < k:\n",
    " \n",
    " \n",
    "     find n pairs\n",
    " \n",
    "     points = rand n\n",
    "     \n",
    "     rotmat,transvec = kabsch(points)\n",
    "     \n",
    "     target_transformed = rotmat*target + transvec\n",
    "     \n",
    "     error = norm2( source, target)\n",
    "     \n",
    "     if error < bestErr then\n",
    "            bestFit := r,t\n",
    "            bestErr := thisErr\n",
    "     end if\n",
    "     \n",
    "     return bestFit\n",
    " \n",
    " ```\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n"
     ]
    }
   ],
   "source": [
    "r1 = o3d.io.read_point_cloud(\"global_registration/r1.pcd\")\n",
    "r2 = o3d.io.read_point_cloud(\"global_registration/r2.pcd\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "voxel_size = 0.05  # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size, r1, r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class with dimension = 33 and num = 4760\n",
      "Access its data via data member.\n"
     ]
    }
   ],
   "source": [
    "print(source_fpfh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = source_fpfh.data\n",
    "t = target_fpfh.data\n",
    "\n",
    "dist_t = np.zeros([target_fpfh.num(),1])\n",
    "index = []\n",
    "\n",
    "\n",
    "for u in range(50):\n",
    "        ps = s[:,u]\n",
    "        \n",
    "        for i in range(target_fpfh.num()):\n",
    "            pt = t[:,i]\n",
    "            dist_t[i] = np.linalg.norm(ps-pt)\n",
    "        \n",
    "        if u>= target_fpfh.num():\n",
    "            break\n",
    "        index.append(np.argmin(dist_t))\n",
    "        \n",
    "            \n",
    "pairs_target_points = np.asarray(target_down.points)[index,:]\n",
    "# print(\"Done\")  \n",
    "# print(\"pairs\",pairs_target_points)\n",
    "# print(\"index\",index)\n",
    "# print(\"target_down\",target_down.points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kabsch(A, B):\n",
    "    assert len(A) == len(B)\n",
    "    \n",
    "    \n",
    "    N = A.shape[0];  # total points\n",
    "\n",
    "    \n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "\n",
    "    # center the points\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "    \n",
    "    H = np.transpose(BB) * AA\n",
    "    \n",
    "    print(H.shape)\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "\n",
    "    R = np.matmul(U,Vt)\n",
    "\n",
    "    t = centroid_B - np.matmul(R, centroid_A)\n",
    "    \n",
    "    return R, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-35c949503ae3>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-35c949503ae3>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    calc error\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 1\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "my_source = np.asarray(source_down.points)\n",
    "my_target = np.asarray(target_down.points)\n",
    "my_index = np.asarray(index)\n",
    "while max_iterations:\n",
    "            max_iterations -= 1\n",
    "            # Add 3 random indexes\n",
    "            random.seed()\n",
    "            inliers = []\n",
    "            n = 3\n",
    "            while len(inliers) < n:\n",
    "                random_index = random.randint(0, 50-1)\n",
    "                #random_index = random.randint(0, len(s[0,:])-1)\n",
    "                inliers.append(random_index)\n",
    "            match_source = my_source[inliers]\n",
    "            my_target_index = my_index[inliers]\n",
    "            match_target = my_target[my_target_index]\n",
    "            print(\"match target\",match_target)\n",
    "            print(\" \")\n",
    "            print(\"match source\",match_source)\n",
    "            \n",
    "            \n",
    "            R,t = Kabsch(match_source,match_target)\n",
    "            \n",
    "            print('Kabsch result:')\n",
    "            print('R:',R)\n",
    "            print('t',t)\n",
    "            \n",
    "            t.resize(3,1)\n",
    "            \n",
    "            target_tranformed = np.dot(R,my_target.T) + t\n",
    "            \n",
    "            calc error\n",
    "            \n",
    "            find best model\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            ax.scatter(my_source[:,0], my_source[:,1],my_source[:,2])\n",
    "            ax.scatter\n",
    "            \n",
    "            \n",
    "            \n",
    "#             error = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
